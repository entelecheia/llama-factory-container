# Sets the base image for subsequent instructions
FROM nvidia/cuda:12.6.3-devel-ubuntu22.04 AS builder

# Sets labels for the image
LABEL org.opencontainers.image.source="https://github.com/entelecheia/llama-factory-container"
LABEL org.opencontainers.image.description="llama-factory-container is a comprehensive AI model training and deployment framework supporting various models, methods, and optimizations."
LABEL org.opencontainers.image.licenses="MIT"

# Setting this argument prevents interactive prompts during the build process
ARG DEBIAN_FRONTEND=noninteractive
# Updates the image and installs necessary packages
RUN apt-get update --fix-missing \
    && apt-get install -y curl wget jq sudo gosu git build-essential software-properties-common \
    locales locales-all fontconfig fonts-nanum \
    python3-pip python3-packaging python3-venv \
    tzdata openssh-server \
    # Cleans up unnecessary packages to reduce image size
    && apt-get autoremove -y \
    && apt-get clean -y

# Create symbolic links for Python and pip
RUN ln -sf /usr/bin/python3.10 /usr/bin/python \
    && ln -sf /usr/bin/python3.10 /usr/bin/python3 \
    && ln -sf /usr/bin/pip3 /usr/bin/pip

# Sets Python environment variables
ENV PIP_DEFAULT_TIMEOUT 100
ENV PYTHONDONTWRITEBYTECODE 1
ENV PYTHONUNBUFFERED 1

# Setting ARGs and ENVs for the app
ARG ARG_APP_INSTALL_ROOT="/opt"
ARG ARG_APP_DIRNAME="entelecheia"
ENV APP_INSTALL_ROOT $ARG_APP_INSTALL_ROOT
ENV APP_DIRNAME $ARG_APP_DIRNAME
ENV APP_SRC_DIR=${APP_INSTALL_ROOT}/${APP_DIRNAME}
ENV APP_VIRTUAL_ENV=${APP_INSTALL_ROOT}/.venvs/${APP_DIRNAME}
ENV PATH="$APP_VIRTUAL_ENV/bin:$PATH"
ENV APP_WORKSPACE_ROOT=${APP_INSTALL_ROOT}/workspace

# Define environments
ENV MAX_JOBS=4
ENV FLASH_ATTENTION_FORCE_BUILD=TRUE
ENV VLLM_WORKER_MULTIPROC_METHOD=spawn

# Define installation arguments
ARG INSTALL_BNB=false
ARG INSTALL_VLLM=false
ARG INSTALL_DEEPSPEED=false
ARG INSTALL_FLASHATTN=false
ARG INSTALL_LIGER_KERNEL=false
ARG INSTALL_HQQ=false
ARG INSTALL_EETQ=false
ARG PIP_INDEX=https://pypi.org/simple

# Set the working directory
WORKDIR ${APP_SRC_DIR}

# Install the requirements
COPY src/LLaMA-Factory/requirements.txt ${APP_SRC_DIR}

# Install pytorch and openllm to the virtual environment
RUN python3 -m venv ${APP_VIRTUAL_ENV} && \
    pip install --upgrade pip setuptools wheel && \
    pip config set global.index-url "$PIP_INDEX" && \
    pip config set global.extra-index-url "$PIP_INDEX" && \
    python3 -m pip install -r requirements.txt

# Copy the rest of the application into the image
COPY src/LLaMA-Factory/ ${APP_SRC_DIR}

# Install the LLaMA Factory
RUN EXTRA_PACKAGES="metrics"; \
    if [ "$INSTALL_BNB" == "true" ]; then \
        EXTRA_PACKAGES="${EXTRA_PACKAGES},bitsandbytes"; \
    fi; \
    if [ "$INSTALL_VLLM" == "true" ]; then \
        EXTRA_PACKAGES="${EXTRA_PACKAGES},vllm"; \
    fi; \
    if [ "$INSTALL_DEEPSPEED" == "true" ]; then \
        EXTRA_PACKAGES="${EXTRA_PACKAGES},deepspeed"; \
    fi; \
    if [ "$INSTALL_LIGER_KERNEL" == "true" ]; then \
        EXTRA_PACKAGES="${EXTRA_PACKAGES},liger-kernel"; \
    fi; \
    if [ "$INSTALL_HQQ" == "true" ]; then \
        EXTRA_PACKAGES="${EXTRA_PACKAGES},hqq"; \
    fi; \
    if [ "$INSTALL_EETQ" == "true" ]; then \
        EXTRA_PACKAGES="${EXTRA_PACKAGES},eetq"; \
    fi; \
    pip install -e ".[$EXTRA_PACKAGES]"

# Rebuild flash attention
RUN pip uninstall -y transformer-engine flash-attn && \
    if [ "$INSTALL_FLASHATTN" == "true" ]; then \
        pip uninstall -y ninja && pip install ninja && \
        pip install --no-cache-dir flash-attn --no-build-isolation; \
    fi

ARG ARG_WORKSPACE_ROOT="/workspace"
ENV WORKSPACE_ROOT $ARG_WORKSPACE_ROOT
# Sets up the workspace for the user
RUN mkdir -p $WORKSPACE_ROOT/projects

# Sets the working directory to workspace root
WORKDIR $WORKSPACE_ROOT
# Copies scripts from host into the image
COPY ./.docker/scripts/ ./scripts/
# RUN pip install -r ./scripts/requirements-dev.txt

# Sets the time zone within the container
ENV TZ="Asia/Seoul"
# Sets up the locale to en_US.UTF-8
RUN localedef -v -c -i en_US -f UTF-8 en_US.UTF-8 || true
    
# Setting ARGs and ENVs for user creation and workspace setup
ARG ARG_USERNAME="dev"
ARG ARG_USER_UID=9001
ARG ARG_USER_GID=$ARG_USER_UID
ENV USERNAME $ARG_USERNAME
ENV USER_UID $ARG_USER_UID
ENV USER_GID $ARG_USER_GID

# Creates a non-root user with sudo privileges
# check if user exists and if not, create user
RUN if id -u $USERNAME >/dev/null 2>&1; then \
        # if the current user's user id is different from the specified user id, change the user id of the current user to the specified user id
        if [ "$USER_UID" -ne "$(id -u $USERNAME)" ]; then \
            usermod --uid $USER_UID $USERNAME; \
            chown --recursive $USER_UID:$USER_UID $WORKSPACE_ROOT; \
            chown --recursive $USER_UID:$USER_UID $APP_INSTALL_ROOT; \
        fi; \
    else \
        groupadd --gid $USER_GID $USERNAME && \
        adduser --uid $USER_UID --gid $USER_GID --force-badname --disabled-password --gecos "" $USERNAME && \
        echo "$USERNAME:$USERNAME" | chpasswd && \
        adduser $USERNAME sudo && \
        echo "$USERNAME ALL=(ALL) NOPASSWD:ALL" >> /etc/sudoers && \
        echo "$USERNAME ALL=(ALL) NOPASSWD:ALL" > /etc/sudoers.d/$USERNAME && \
        chmod 0440 /etc/sudoers.d/$USERNAME; \
    fi


USER root

# Copies entrypoint script from host into the image
COPY ./.docker/scripts/entrypoint.sh /usr/local/bin/entrypoint.sh
# Changes the entrypoint script permissions to make it executable
RUN chmod +x /usr/local/bin/entrypoint.sh
# Sets the entrypoint script as the default command that will be executed when the container is run
ENTRYPOINT ["/usr/local/bin/entrypoint.sh"]

# Expose port 7860 for the LLaMA Board
ENV GRADIO_SERVER_PORT 7860
EXPOSE 7860

# Expose port 8000 for the API service
ENV API_PORT 8000
EXPOSE 8000

# Specifies the command that will be executed when the container is run
CMD ["bash"]
